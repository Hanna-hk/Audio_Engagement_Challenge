{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7aeb4a8",
   "metadata": {},
   "source": [
    "**Structure**\n",
    "--\n",
    "1. Data Collection\n",
    "2. Data Cleaning, Data Binning and Label Encoding\n",
    "3. Model Choosing\n",
    "4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2c87f",
   "metadata": {},
   "source": [
    "**1. Data Collection**\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c462caa",
   "metadata": {},
   "source": [
    "**Import Data and Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb0049e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statistics\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor, RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22abb42",
   "metadata": {},
   "source": [
    "**Import the CSV Data as Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cf4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded in 2.507091760635376 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "print(\"Files loaded in\", time.time()-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1957fe",
   "metadata": {},
   "source": [
    "**2. Data Cleaning, Data Binning and Label Encoding**\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b243d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'Listening_Time_minutes'], axis=1)\n",
    "Y_train = train['Listening_Time_minutes']\n",
    "X_test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30e6e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Number_of_Ads']=X_train['Number_of_Ads'].fillna(X_train['Number_of_Ads'].median())\n",
    "X_train['Number_of_Ads'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944d770",
   "metadata": {},
   "source": [
    "**Replacing nullable data in `Guest_Popularity_percentage` with 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528bee05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Guest_Popularity_percentage']=X_train['Guest_Popularity_percentage'].fillna(0)\n",
    "X_train['Guest_Popularity_percentage'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f222c856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Guest_Popularity_percentage']=X_test['Guest_Popularity_percentage'].fillna(0)\n",
    "X_test['Guest_Popularity_percentage'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54097f26",
   "metadata": {},
   "source": [
    "**Using Simple Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c76c9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has been transformed\n",
      "Testing data has been transformed\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "num_without_id = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
    "X_train[num_without_id] = imputer.fit_transform(train[num_without_id])\n",
    "print(f\"Training data has been transformed\")\n",
    "X_test[num_without_id] = imputer.transform(test[num_without_id])\n",
    "print(f\"Testing data has been transformed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c193b8f",
   "metadata": {},
   "source": [
    "**Handling outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92748cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomalies(data):\n",
    "    anomalies=[]\n",
    "    data_std = statistics.stdev(data)\n",
    "    data_mean = statistics.mean(data)\n",
    "    anomaly_cut_off = data_std * 3\n",
    "    lower_limit = data_mean - anomaly_cut_off\n",
    "    upper_limit = data_mean +anomaly_cut_off\n",
    "    for outlier in data:\n",
    "        if outlier > upper_limit or outlier < lower_limit:\n",
    "            anomalies.append(outlier)\n",
    "            print(f\"The value of the outlier: {outlier}\")\n",
    "    return anomalies\n",
    "\n",
    "def list_outliers(data, columns):\n",
    "    anomalies = []\n",
    "    for col in columns:\n",
    "        outliers = find_anomalies(data[col])\n",
    "        print(f\"In the {col} column there are {len(outliers)} outliers\")\n",
    "        anomalies.append((col, outliers))\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e624979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train outliers:\n",
      "The value of the outlier: 325.24\n",
      "In the Episode_Length_minutes column there are 1 outliers\n",
      "In the Host_Popularity_percentage column there are 0 outliers\n",
      "In the Guest_Popularity_percentage column there are 0 outliers\n",
      "The value of the outlier: 53.37\n",
      "The value of the outlier: 103.91\n",
      "The value of the outlier: 103.0\n",
      "The value of the outlier: 53.42\n",
      "The value of the outlier: 103.75\n",
      "The value of the outlier: 12.0\n",
      "The value of the outlier: 103.25\n",
      "The value of the outlier: 103.25\n",
      "The value of the outlier: 103.88\n",
      "In the Number_of_Ads column there are 9 outliers\n",
      "Test outliers:\n",
      "The value of the outlier: 78486264.0\n",
      "In the Episode_Length_minutes column there are 1 outliers\n",
      "In the Host_Popularity_percentage column there are 0 outliers\n",
      "In the Guest_Popularity_percentage column there are 0 outliers\n",
      "The value of the outlier: 89.12\n",
      "The value of the outlier: 2063.0\n",
      "In the Number_of_Ads column there are 2 outliers\n"
     ]
    }
   ],
   "source": [
    "print(\"Train outliers:\")\n",
    "train_anomalies = list_outliers(X_train, num_without_id)\n",
    "print(\"Test outliers:\")\n",
    "test_anomalies = list_outliers(X_test, num_without_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1154b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(data, value_up, value_low, columns):\n",
    "    data_copy = data.copy()\n",
    "    for column in columns:\n",
    "        up_mask = data_copy[column] > value_up\n",
    "        if up_mask.any():\n",
    "            data_copy.loc[up_mask, column] = value_up\n",
    "            print(f\"{column}: replaced {up_mask.sum()} values with {value_up}\")\n",
    "        low_mask = data_copy[column] < value_low\n",
    "        if low_mask.any():\n",
    "            data_copy.loc[low_mask, column] = value_low\n",
    "            print(f\"{column}: replaced {low_mask.sum()} values with {value_low}\")\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906b858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guest_Popularity_percentage: replaced 19 values with 100\n",
      "Host_Popularity_percentage: replaced 25 values with 100\n",
      "Guest_Popularity_percentage: replaced 5 values with 100\n",
      "Host_Popularity_percentage: replaced 12 values with 100\n"
     ]
    }
   ],
   "source": [
    "X_train_num = X_train[num_without_id]\n",
    "X_test_num = X_test[num_without_id]\n",
    "percentage_cols = ['Guest_Popularity_percentage', 'Host_Popularity_percentage']\n",
    "X_train[num_without_id]= replace(X_train_num, 100,0,percentage_cols)\n",
    "X_test[num_without_id] = replace(X_test_num, 100,0,percentage_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c413f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(train_data, test_data, columns):\n",
    "    data_replaced_train = train_data.copy()\n",
    "    data_replaced_test = test_data.copy()\n",
    "    for column in columns:\n",
    "        col_data_train = train_data[column]\n",
    "        data_std = statistics.stdev(col_data_train)\n",
    "        data_mean = statistics.mean(col_data_train)\n",
    "        anomaly_cut_off = data_std * 3\n",
    "        lower_limit = round(data_mean - anomaly_cut_off, 2)\n",
    "        upper_limit = round(data_mean + anomaly_cut_off, 2)\n",
    "        data_replaced_train = replace(data_replaced_train, upper_limit, lower_limit, [column])\n",
    "        data_replaced_test = replace(data_replaced_test, upper_limit, lower_limit, [column])\n",
    "    return data_replaced_train, data_replaced_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "147d04e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode_Length_minutes: replaced 1 values with 157.42\n",
      "Episode_Length_minutes: replaced 2 values with 157.42\n",
      "Number_of_Ads: replaced 9 values with 4.8\n",
      "Number_of_Ads: replaced 2 values with 4.8\n"
     ]
    }
   ],
   "source": [
    "outlier_cols = ['Episode_Length_minutes', 'Number_of_Ads']\n",
    "X_train_replaced, X_test_replaced = replace_outliers(X_train, X_test, outlier_cols)\n",
    "X_train_replaced = X_train_replaced.round({'Number_of_Ads':0})\n",
    "X_test_replaced = X_test_replaced.round({'Number_of_Ads':0})\n",
    "X_test = X_test_replaced\n",
    "X_train = X_train_replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921db06b",
   "metadata": {},
   "source": [
    "**`Episode_Title` to numerical column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e4c37c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98\n",
       "1    26\n",
       "2    16\n",
       "3    45\n",
       "4    86\n",
       "Name: Episode_Title, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Episode_Title'] = X_train['Episode_Title'].str.extract('(\\d+)').astype(int)\n",
    "X_train['Episode_Title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "275124af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73\n",
       "1    23\n",
       "2    11\n",
       "3    73\n",
       "4    50\n",
       "Name: Episode_Title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Episode_Title'] = X_test['Episode_Title'].str.extract('(\\d+)').astype(int)\n",
    "X_test['Episode_Title'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3de14",
   "metadata": {},
   "source": [
    "**Feature Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17b9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Ads_per_Popularity'] = X_train['Number_of_Ads'] / (X_train['Host_Popularity_percentage'] + 0.1)\n",
    "X_test['Ads_per_Popularity'] = X_test['Number_of_Ads'] / (X_test['Host_Popularity_percentage'] + 0.1)\n",
    "X_train['Length_Ads_Ratio'] = X_train['Episode_Length_minutes'] / (X_train['Number_of_Ads'] + 1)\n",
    "X_test['Length_Ads_Ratio'] = X_test['Episode_Length_minutes'] / (X_test['Number_of_Ads'] + 1)\n",
    "X_train['Length_Popularity_Interaction'] = X_train['Episode_Length_minutes'] * (X_train['Host_Popularity_percentage']+X_train['Guest_Popularity_percentage'])\n",
    "X_test['Length_Popularity_Interaction'] = X_test['Episode_Length_minutes'] * (X_test['Host_Popularity_percentage']+X_test['Guest_Popularity_percentage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705af3da",
   "metadata": {},
   "source": [
    "**Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c6a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns = ['Episode_Sentiment', 'Publication_Day', 'Publication_Time', 'Podcast_Name', 'Genre']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in ordinal_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[f'{col}_Encoded'] = le.fit_transform(X_train[col])\n",
    "    X_test[f'{col}_Encoded'] = le.transform(X_test[col])\n",
    "    label_encoders[col] = le\n",
    "X_train = X_train.drop(ordinal_columns, axis=1)\n",
    "X_test = X_test.drop(ordinal_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317f2a8",
   "metadata": {},
   "source": [
    "**3. Model Choosing**\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f85c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters for RandomForest was found: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 124}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "def create_and_validate_ensemble(X_train, y_train, test_size=0.2):\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    voting_ensemble = VotingRegressor([\n",
    "        ('lgb', LGBMRegressor(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=7,\n",
    "            num_leaves=63,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )),\n",
    "        ('xgb', XGBRegressor(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=7,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )),\n",
    "        ('cat', CatBoostRegressor(\n",
    "            iterations=1000,\n",
    "            learning_rate=0.05,\n",
    "            depth=7,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        ))\n",
    "    ])\n",
    "    stacking_ensemble = StackingRegressor([\n",
    "        ('lgb', LGBMRegressor(\n",
    "            n_estimators=800,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        )),\n",
    "        ('xgb', XGBRegressor(\n",
    "            n_estimators=800,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ], final_estimator=Ridge(alpha=1.0), cv=3)\n",
    "    \n",
    "\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 200),\n",
    "        'max_depth': [10, 15, None],\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf, param_dist, n_iter=8, cv=3,\n",
    "        n_jobs=-1, verbose=1, random_state=42\n",
    "    )\n",
    "    random_search.fit(X_tr, y_tr)\n",
    "    best_rf_params = random_search.best_params_\n",
    "    print(f'Best parameters for RandomForest was found: {best_rf_params}')\n",
    "    \n",
    "    models = {\n",
    "        'LightGBM': LGBMRegressor(n_estimators=1000, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=1000, random_state=42),\n",
    "        'Voting_Ensemble': voting_ensemble,\n",
    "        'Stacking_Ensemble': stacking_ensemble,\n",
    "        'RandomForest': RandomForestRegressor(**best_rf_params, random_state=42)\n",
    "    }\n",
    "    return models, X_tr, X_val, y_tr, y_val\n",
    "\n",
    "models, X_tr, X_val, y_tr, y_val = create_and_validate_ensemble(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e404483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING AND MODEL EVALUATION ===\n",
      "\n",
      "--- MODEL TRAINING RandomForest ---\n",
      "RMSE: 12.6730\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(models, X_tr, X_val, y_tr, y_val):\n",
    "    results = {}\n",
    "    \n",
    "    print(\"=== TRAINING AND MODEL EVALUATION ===\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- MODEL TRAINING {name} ---\")\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'rmse': rmse,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = evaluate_models(models, X_tr, X_val, y_tr, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a9b421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = min(results, key=lambda x: results[x]['rmse'])\n",
    "best_result = results[best_model_name]\n",
    "best_model = best_result['model']\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18f84a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions were saved in predictions.csv\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'id': range(750000, 750000 + len(y_pred)),\n",
    "    'Listening_Time_minutes': y_pred\n",
    "})\n",
    "\n",
    "results.to_csv('sample_submission.csv', index=False, float_format='%.3f')\n",
    "print(\"Predictions were saved in predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
